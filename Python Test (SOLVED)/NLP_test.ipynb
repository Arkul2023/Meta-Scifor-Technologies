{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548cce1e-1397-41c4-98e2-95d7710a3392",
   "metadata": {},
   "source": [
    "#### NLTK (Natural Language Toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35c0a9-47f7-407b-9e5e-7635bd0ed499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you tokenize a sentence into words using NLTK?\n",
    "\n",
    "# -First we import nltk library. Then import word_tokenize from nltk.tokenize.\n",
    "# -Then download \"punkt\" from nltk.\n",
    "# -Then take an example sentence.\n",
    "# -Next tokenize the sentence using word_tokenize() method and print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41516b77-d641-491d-8f23-538a841b644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you remove stopwords from a text using NLTK?\n",
    "\n",
    "# First we need to tokenize the words in the sentence\n",
    "# Then nltk provides pre-defined list of stopwords from multiple languages access that\n",
    "# Then compare each word in the tokenized text and remove the stopwords if found any in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c90fc-3654-4b89-a2c0-8f22eb80660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you perform stemming in NLTK? Provide an example.\n",
    "\n",
    "# Stemming is a technique where we need to reduce the word to its root form\n",
    "# It can be done with the help of Porterstem algorithm\n",
    "# It helps in reducing the dimensionality of text data, making it useful in applications like text classification.\n",
    "# First import library. Then Create instance stemmer = PorterStemmer()\n",
    "# stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "# For example - running -- run, easily -- easili, generously -- generousli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28d899-8c9b-4137-8e65-5826ec1868f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  What is the difference between stemming and lemmatization in NLTK?\n",
    "\n",
    "# Stemming is faster as compared to lemmatization\n",
    "# But stemming is less accurate while lemmatization is more accurate\n",
    "# Lemmatization reduces the word to a dictionary form considering the context and meaning.\n",
    "# Stemming does not have meaningful words all the time \n",
    "# But lemmatization has meaningful words. For Example- studies -- study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f923b-8f76-4c4e-b11b-5c9a5e8f4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you perform part-of-speech (POS) tagging using NLTK?\n",
    "\n",
    "# Part-of-Speech (POS) tagging is the process of assigning grammatical categories to each word in a given text.\n",
    "# It helps computers understand the role of each word in a sentence,\n",
    "# which is crucial for Natural Language Processing (NLP) tasks like text analysis, speech recognition, sentiment analysis, and machine translation.\n",
    "\n",
    "# For example, in the sentence:\n",
    "# \"The cat sleeps on the mat.\"\n",
    "# POS tagging assigns:\n",
    "\n",
    "# The → Determiner (DT)\n",
    "# cat → Noun (NN)\n",
    "# sleeps → Verb (VBZ)\n",
    "# on → Preposition (IN)\n",
    "# the → Determiner (DT)\n",
    "# mat → Noun (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314caccf-fd5e-4496-8cf9-6efa2e8bf7a8",
   "metadata": {},
   "source": [
    "#### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922cdfe1-e860-44bf-8614-dae0f9290bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you load an English language model in spaCy?\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")  # Load the English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399c979-66a2-4de8-b684-e7493329faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you extract named entities (NER) from a text using spaCy?\n",
    "\n",
    "# NER basically satands for named entity recognition\n",
    "# It identifies or recognise the text data what is actually into person, object or anything\n",
    "# For example - Apple Inc. → ORG (Organization)\n",
    "# Steve Jobs → PERSON (Person)\n",
    "# California → GPE (Geopolitical Entity - City/State/Country)\n",
    "# 1976 → DATE\n",
    "\n",
    "# Extraction - import spacy\n",
    "# load the english model\n",
    "# text = \" \"\n",
    "# doc = nlp.(text)\n",
    "# Extract the named entities for ent in doc.ents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c95bee-e8de-47f2-83c2-ed496418e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you find the dependency relations between words using spaCy?\n",
    "\n",
    "# In spaCy, dependency relations between words in a sentence are determined using dependency parsing.\n",
    "# Which analyzes the grammatical structure of the sentence and assigns relationships between words.\n",
    "# Spacy uses a pretrained statistical models to assign the syntactic structure of the sentence.\n",
    "# It identifies a head (governing word) and dependent (modifier) for each token.\n",
    "# The parser constructs a dependency tree, where:\n",
    "# The root is the main verb or governing word.\n",
    "# Each word is connected to its syntactic head with a labeled dependency arc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db119be-be18-4af9-af80-3ac5cdfedce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you perform sentence segmentation in spaCy?\n",
    "\n",
    "# Sentence segmentation refers to the process of splitting a text into individual sentences.\n",
    "# sentence segmentation is performed during the tokenization process.\n",
    "# Basically segments text into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4716699-efe6-4c5e-8a1d-b85fd0f68270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you check if a word is a stopword in spaCy?\n",
    "\n",
    "# stopwords are common words (like \"the,\" \"is,\" \"in,\" \"and,\" etc.) \n",
    "# That are usually removed during natural language processing (NLP) tasks to reduce noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0303c8b8-ad57-44cd-b741-82fb7f1d9947",
   "metadata": {},
   "source": [
    "#### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc547d-e530-4411-8c37-fbaa58ef4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you compute the sentiment polarity of a text using TextBlob?\n",
    "\n",
    "# Generally sentiment polarity is detected using \"blob.sentiment.polarity\" method build-in in textblob\n",
    "## If the polarity score is P>0 (positive)\n",
    "                        ##  P<0 (negative)\n",
    "                        ##  P=0 (neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ace70f-c68c-4453-b112-6ccd9180d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you perform spelling correction using TextBlob?\n",
    "\n",
    "# from textblob import TextBlob\n",
    "\n",
    "# # Input text with spelling mistakes\n",
    "# text = \"I am verry hapy today!\"\n",
    "\n",
    "# # Create a TextBlob object\n",
    "# blob = TextBlob(text)\n",
    "\n",
    "# # Perform spelling correction\n",
    "# corrected_text = blob.correct()\n",
    "\n",
    "# print(text)\n",
    "# print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42c2f1-9524-4283-ae83-452e14c96564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you get noun phrases from a sentence using TextBlob?\n",
    "\n",
    "# First we need to do Tokenization where the text is split into words and phrases.\n",
    "# Then Part-of-Speech (POS) Tagging where each word is tagged (e.g., noun, verb, adjective).\n",
    "# Then Noun Phrase Extraction which uses shallow parsing (chunking) to identify noun phrases (like \"big house\", \"artificial intelligence\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048b384-2f37-46ef-9018-0e5de777a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you translate a text from English to another language using TextBlob?\n",
    "\n",
    "# from textblob import TextBlob\n",
    "\n",
    "# # Input text in English\n",
    "# text = \"Hello, how are you?\"\n",
    "\n",
    "# # Create a TextBlob object\n",
    "# blob = TextBlob(text)\n",
    "\n",
    "# # Translate to Spanish\n",
    "# translated_text = blob.translate(to='es')\n",
    "\n",
    "# print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157748d-ea27-4df0-b887-fb6c114d9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you detect the language of a given text using TextBlob?\n",
    "\n",
    "# from textblob import TextBlob\n",
    "\n",
    "# # Input text in an unknown language\n",
    "# text = \"Bonjour, comment ça va?\"\n",
    "\n",
    "# # Create a TextBlob object\n",
    "# blob = TextBlob(text)\n",
    "\n",
    "# # Detect language\n",
    "# detected_language = blob.detect_language()\n",
    "\n",
    "# print(detected_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e475d16-5beb-4e0b-b02d-116c06ed4c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b2acd-ca4d-4fd3-b632-83ed85d64d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4946526a-ca05-43b6-8e07-e9f303f03cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 524.3/624.3 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 524.3/624.3 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 524.3/624.3 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 524.3/624.3 kB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- 624.3/624.3 kB 374.1 kB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e80cc26-9554-4110-9806-541f1bd20cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 90.0%\n",
      "Review: I love the camera, it clicks amazing pictures!\n",
      "Actual Sentiment: pos | Predicted Sentiment: pos\n",
      "\n",
      "Review: Battery backup is disappointing, drains quickly.\n",
      "Actual Sentiment: neg | Predicted Sentiment: neg\n",
      "\n",
      "Review: The display is very bright and vibrant.\n",
      "Actual Sentiment: pos | Predicted Sentiment: pos\n",
      "\n",
      "Review: Phone lags when switching between apps.\n",
      "Actual Sentiment: neg | Predicted Sentiment: neg\n",
      "\n",
      "Review: Very stylish and premium-looking design.\n",
      "Actual Sentiment: pos | Predicted Sentiment: pos\n",
      "\n",
      "Review: Face unlock doesn't work properly.\n",
      "Actual Sentiment: neg | Predicted Sentiment: pos\n",
      "\n",
      "Review: The performance is super smooth!\n",
      "Actual Sentiment: pos | Predicted Sentiment: pos\n",
      "\n",
      "Review: Charging speed is very slow, takes ages.\n",
      "Actual Sentiment: neg | Predicted Sentiment: neg\n",
      "\n",
      "Review: Call quality is excellent, voice is very clear.\n",
      "Actual Sentiment: pos | Predicted Sentiment: pos\n",
      "\n",
      "Review: The phone keeps hanging, very frustrating.\n",
      "Actual Sentiment: neg | Predicted Sentiment: neg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Training data\n",
    "train = [\n",
    "    (\"This phone is amazing, I love the camera!\", \"pos\"),\n",
    "    (\"Battery life is superb, lasts more than a day.\", \"pos\"),\n",
    "    (\"The display quality is top-notch.\", \"pos\"),\n",
    "    (\"Fast charging works like a charm!\", \"pos\"),\n",
    "    (\"Very smooth performance and no lag.\", \"pos\"),\n",
    "    (\"Great phone at this price range.\", \"pos\"),\n",
    "    (\"I am highly satisfied with the features.\", \"pos\"),\n",
    "    (\"Audio quality is crystal clear.\", \"pos\"),\n",
    "    (\"Superb design and looks premium.\", \"pos\"),\n",
    "    (\"Face unlock is super fast.\", \"pos\"),\n",
    "    (\"I regret buying this phone, worst experience.\", \"neg\"),\n",
    "    (\"Battery drains too fast, not recommended.\", \"neg\"),\n",
    "    (\"Overheating issue while gaming, disappointing.\", \"neg\"),\n",
    "    (\"Camera quality is terrible in low light.\", \"neg\"),\n",
    "    (\"Too many ads in the UI, very annoying.\", \"neg\"),\n",
    "    (\"Fingerprint sensor is slow and unresponsive.\", \"neg\"),\n",
    "    (\"Touchscreen sometimes freezes.\", \"neg\"),\n",
    "    (\"Speaker volume is too low.\", \"neg\"),\n",
    "    (\"Performance is sluggish, lags a lot.\", \"neg\"),\n",
    "    (\"Build quality feels very cheap.\", \"neg\"),\n",
    "    (\"The phone is very lightweight and easy to hold.\", \"pos\"),\n",
    "    (\"I love the color and design of this phone.\", \"pos\"),\n",
    "    (\"The UI is clean and easy to use.\", \"pos\"),\n",
    "    (\"Gaming performance is fantastic.\", \"pos\"),\n",
    "    (\"Storage capacity is more than enough.\", \"pos\"),\n",
    "    (\"This phone is a complete package!\", \"pos\"),\n",
    "    (\"Good for video calling, camera quality is decent.\", \"pos\"),\n",
    "    (\"5G connectivity works smoothly.\", \"pos\"),\n",
    "    (\"This phone exceeded my expectations.\", \"pos\"),\n",
    "    (\"The processor is fast and efficient.\", \"pos\"),\n",
    "    (\"Network issues, keeps disconnecting.\", \"neg\"),\n",
    "    (\"Screen started flickering after a few days.\", \"neg\"),\n",
    "    (\"The phone heats up even with normal usage.\", \"neg\"),\n",
    "    (\"No software updates, outdated security patches.\", \"neg\"),\n",
    "    (\"Customer support is unhelpful.\", \"neg\"),\n",
    "    (\"Charger stopped working within a month.\", \"neg\"),\n",
    "    (\"Speakers produce distorted sound.\", \"neg\"),\n",
    "    (\"Camera app crashes frequently.\", \"neg\"),\n",
    "    (\"Poor optimization, apps take forever to load.\", \"neg\"),\n",
    "    (\"Too heavy to hold for long hours.\", \"neg\")\n",
    "]\n",
    "\n",
    "# Test data\n",
    "test = [\n",
    "    (\"I love the camera, it clicks amazing pictures!\", \"pos\"),\n",
    "    (\"Battery backup is disappointing, drains quickly.\", \"neg\"),\n",
    "    (\"The display is very bright and vibrant.\", \"pos\"),\n",
    "    (\"Phone lags when switching between apps.\", \"neg\"),\n",
    "    (\"Very stylish and premium-looking design.\", \"pos\"),\n",
    "    (\"Face unlock doesn't work properly.\", \"neg\"),\n",
    "    (\"The performance is super smooth!\", \"pos\"),\n",
    "    (\"Charging speed is very slow, takes ages.\", \"neg\"),\n",
    "    (\"Call quality is excellent, voice is very clear.\", \"pos\"),\n",
    "    (\"The phone keeps hanging, very frustrating.\", \"neg\")\n",
    "]\n",
    "\n",
    "# Train the classifier\n",
    "classifier = NaiveBayesClassifier(train)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = classifier.accuracy(test)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Model Accuracy: {accuracy * 100}%\")  ##Here 'f' represents formatted string.\n",
    "\n",
    "# Predict sentiment for test data\n",
    "for review, actual in test:\n",
    "    predicted = classifier.classify(review) ## .classify() is a method to classify the statement into positive or negative\n",
    "    print(f\"Review: {review}\\nActual Sentiment: {actual} | Predicted Sentiment: {predicted}\\n\")  ## Here \\n represents printing output 1 line below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697676c9-18d8-4e86-aec4-f7d9adc2d95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
